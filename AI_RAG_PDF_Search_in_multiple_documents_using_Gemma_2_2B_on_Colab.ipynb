{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriciocarraro/AI_RAG_PDF_Search_in_multiple_documents_using_Gemma_2_2B_on_Colab/blob/main/AI_RAG_PDF_Search_in_multiple_documents_using_Gemma_2_2B_on_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IoMifO9JvDn"
      },
      "source": [
        "# RAG - PDF Search in multiple documents using Gemma 2 2B on Colab\n",
        "\n",
        "This project demonstrates a pipeline for extracting, processing, and querying text data from PDF documents on Google Colab using natural language processing (NLP) techniques and Google's open-source model Gemma 2 2B. The system allows users to input a query, which is then answered based on the content of the PDFs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3Kk2dPyJvDq"
      },
      "source": [
        "## Setup\n",
        "### Select the Colab runtime\n",
        "\n",
        "To complete this tutorial, you'll need to have a Colab runtime with sufficient resources to run the Gemma model. In this case, you can use a T4 GPU:\n",
        "\n",
        "1. In the upper-right of the Colab window, select **â–¾ (Additional connection options)**.\n",
        "2. Select **Change runtime type**.\n",
        "3. Under **Hardware accelerator**, select **T4 GPU**.\n",
        "\n",
        "### Gemma 2 setup on Hugging Face\n",
        "\n",
        "This cookbook uses Gemma 2B instruction tuned model through Hugging Face. So you will need to:\n",
        "\n",
        "* Get access to Gemma 2 on [huggingface.co](huggingface.co) by accepting the Gemma 2 license on the Hugging Face page of the specific model, i.e., [Gemma 2B IT](https://huggingface.co/google/gemma-2-2b-it).\n",
        "* Generate a [Hugging Face access token](https://huggingface.co/docs/hub/en/security-tokens) and configure it as a Colab secret 'HF_TOKEN'.\n",
        "\n",
        "## Retrieval-Augmented Generation (RAG)\n",
        "\n",
        "Large Language Models (LLMs) can learn new abilities without directly being trained on them. However, LLMs have been known to \"hallucinate\" when tasked with providing responses for questions they have not been trained on. This is partly because LLMs are unaware of events after training. It is also very difficult to trace the sources from which LLMs draw their responses from. For reliable, scalable applications, it is important that an LLM provides responses that are grounded in facts and is able to cite its information sources.\n",
        "\n",
        "A common approach used to overcome these constraints is called Retrieval Augmented Generation (RAG), which augments the prompt sent to an LLM with relevant data retrieved from an external knowledge base through an Information Retrieval (IR) mechanism. The knowledge base can be your own corpora of documents, databases, or APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx6PsqYRJvDr"
      },
      "source": [
        "## Installing and importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_2ac23WaxVGR"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers sentence_transformers faiss-cpu torch PyPDF2 nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxlPGnyo0lei",
        "outputId": "83092d7b-91be-467d-e4c7-a91d3aa12220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPcdyapHJvDt"
      },
      "source": [
        "## Setting up the model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "629d58acfb1d4b04b1b44391c35bc469",
            "4bd92400b09b4067a682fcfa2d1abf69",
            "8ca9341fc87c430fa398b2affa3c3fc5",
            "9b1d1adfc800468a8e0dd45dcea31ed1",
            "31c63eb1029744cfaf0b6975484e2f7f",
            "d77dd6626fe747e6869558b9083f4b43",
            "6bc35900d38e467cb647d80bc58c6add",
            "04b85362a05d47639832ddb43cbe4d61",
            "d59bb55498a44e9583d36359c7dfd194",
            "a22824f74ba343bd8ed6193dc53033a8",
            "feef4d5202624afbb84c16d20a1b271b"
          ]
        },
        "id": "rQulEL_Ry-J4",
        "outputId": "66ae8d4b-f12c-4522-a95d-31adb560e5b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "629d58acfb1d4b04b1b44391c35bc469"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "HUGGING_FACE_ACCESS_TOKEN = userdata.get('HUGGING_FACE_ACCESS_TOKEN')\n",
        "\n",
        "model_name = 'google/gemma-2-2b-it'\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    token=HUGGING_FACE_ACCESS_TOKEN\n",
        "    ).to('cuda')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=HUGGING_FACE_ACCESS_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7WJmvSKJvDu"
      },
      "source": [
        "## Extracting and tokenizing info from the PDF files\n",
        "\n",
        "The `extract_text_from_pdf()` function will look for all PDF files in the `pdf_path` folder.\n",
        "\n",
        "The `split_text_into_chunks()` function gets the text and breaks it down into smaller chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-JBcrxgxx9Fg"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\".join([page.extract_text() for page in reader.pages])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {pdf_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def split_text_into_chunks(text, max_chunk_size=1000):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) <= max_chunk_size:\n",
        "            current_chunk += sentence + \" \"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \" \"\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPhLG_ltJvDv"
      },
      "source": [
        "## Extracting info from the PDFs\n",
        "\n",
        "Set the variable `pdf_directory` with the path where your PDF files are. In this case, running on Google Colab, they would be in a folder called `PDFs`, that can be created on the content area on the left side.\n",
        "\n",
        "A Pandas DataFrame is created containing the path of the corresponding PDF, its chunks and the embedding vector of its chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjPD3LOfHYdg",
        "outputId": "ec1b6032-fdc1-4b03-c9b7-89076d83a4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ticket_to_ride.pdf\n",
            "monopoly.pdf\n"
          ]
        }
      ],
      "source": [
        "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Process PDF files\n",
        "pdf_directory = \"/content/PDFs/\" # Create the /PDF folder inside your Google Colab files page\n",
        "df_documents = pd.DataFrame(columns=['path', 'text_chunks', 'embeddings'])\n",
        "\n",
        "for filename in os.listdir(pdf_directory):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        print(filename)\n",
        "        pdf_path = os.path.join(pdf_directory, filename)\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        chunks = split_text_into_chunks(text)\n",
        "        document_embeddings = encoder.encode(chunks)\n",
        "        new_row = pd.DataFrame({'path': [pdf_path], 'text_chunks': [chunks], 'embeddings': [document_embeddings]})\n",
        "        df_documents = pd.concat([df_documents, new_row], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "def trunc(cell, width=50):\n",
        "    s = str(cell)\n",
        "    return s if len(s) <= width else s[:width] + \"â€¦\"\n",
        "\n",
        "styled_df_documents = (df_documents.style.format(trunc).set_table_styles([{'selector': 'th', 'props': [('text-align', 'right')]}]))\n",
        "\n",
        "HTML(styled_df_documents.to_html())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "CtCn7Th7x1Zr",
        "outputId": "0b2d515d-3131-4a31-abda-fa3ff139f863"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_ffd1f th {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_ffd1f\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_ffd1f_level0_col0\" class=\"col_heading level0 col0\" >path</th>\n",
              "      <th id=\"T_ffd1f_level0_col1\" class=\"col_heading level0 col1\" >text_chunks</th>\n",
              "      <th id=\"T_ffd1f_level0_col2\" class=\"col_heading level0 col2\" >embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_ffd1f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_ffd1f_row0_col0\" class=\"data row0 col0\" >/content/PDFs/ticket_to_ride.pdf</td>\n",
              "      <td id=\"T_ffd1f_row0_col1\" class=\"data row0 col1\" >['On a blustery autumn evening five old friends meâ€¦</td>\n",
              "      <td id=\"T_ffd1f_row0_col2\" class=\"data row0 col2\" >[[ 0.03247902  0.0315639   0.09368591 ... -0.04949â€¦</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ffd1f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_ffd1f_row1_col0\" class=\"data row1 col0\" >/content/PDFs/monopoly.pdf</td>\n",
              "      <td id=\"T_ffd1f_row1_col1\" class=\"data row1 col1\" >['MONOPOLY \\nProperty Trading Game from Parker Broâ€¦</td>\n",
              "      <td id=\"T_ffd1f_row1_col2\" class=\"data row1 col2\" >[[ 0.03459294 -0.00450069 -0.04992099 ... -0.02507â€¦</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoNyQBdyJvDv"
      },
      "source": [
        "## Creating a FAISS index from all document embeddings\n",
        "\n",
        "Faiss is a library for efficient similarity search and clustering of vectors. The IndexFlatL2 algorithm will be applied to all chunk embedding vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Vsp1NhGNPyJb"
      },
      "outputs": [],
      "source": [
        "# Create a FAISS index from all document embeddings\n",
        "all_embeddings = np.vstack(df_documents['embeddings'].tolist())\n",
        "dimension = all_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(all_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZKOXGd2JvDw"
      },
      "source": [
        "## Calculating the embedding distance and generating an answer\n",
        "\n",
        "The `find_most_similar_chunks()` function will create an embedding vector for your query and compare its similarity to all the chunks it retrieved from the PDF files, returning the most similar one, which will be used as the context for the next function.\n",
        "\n",
        "The `generate_response()` function will generate an answer using our selected model (Gemma 2 2B) based on the context retrieved from the most similar info chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6TxTcBlnHo_v"
      },
      "outputs": [],
      "source": [
        "def find_most_similar_chunks(query, top_k=3):\n",
        "    query_embedding = encoder.encode([query])\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    results = []\n",
        "    total_chunks = sum(len(chunks) for chunks in df_documents['text_chunks'])\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        if idx < total_chunks:\n",
        "            doc_idx = 0\n",
        "            chunk_idx = idx\n",
        "            while chunk_idx >= len(df_documents['text_chunks'].iloc[doc_idx]):\n",
        "                chunk_idx -= len(df_documents['text_chunks'].iloc[doc_idx])\n",
        "                doc_idx += 1\n",
        "            results.append({\n",
        "                'document': df_documents['path'].iloc[doc_idx],\n",
        "                'chunk': df_documents['text_chunks'].iloc[doc_idx][chunk_idx],\n",
        "                'distance': distances[0][i]\n",
        "            })\n",
        "    return results\n",
        "\n",
        "def generate_response(query, context, max_length=1000):\n",
        "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(input_ids, max_new_tokens=max_length, num_return_sequences=1)\n",
        "\n",
        "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extracting the answer part by removing the prompt portion\n",
        "    answer_start = decoded_output.find(\"Answer:\") + len(\"Answer:\")\n",
        "    answer = decoded_output[answer_start:].strip()\n",
        "\n",
        "    return answer\n",
        "\n",
        "def query_documents(query):\n",
        "    similar_chunks = find_most_similar_chunks(query)\n",
        "    context = \" \".join([result['chunk'].replace(\"\\n\", \"\") for result in similar_chunks])\n",
        "    response = generate_response(query, context)\n",
        "    return response, similar_chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQBk7vDjJvDw"
      },
      "source": [
        "## Looking for info in the PDFs\n",
        "\n",
        "The variable `query` contains the information you want to retrieve from the PDF files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKLnKXHKHxe4",
        "outputId": "38d6787d-e97e-4a10-f335-3bdb2c7faae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How many types of regular Train Car cards are there?\n",
            "\n",
            "-----\n",
            "\n",
            "Generated answer: There are 8 types of regular Train Car cards.\n",
            "\n",
            "-----\n",
            "\n",
            "Relevant chunks:\n",
            "Document: /content/PDFs/ticket_to_ride.pdf\n",
            "Chunk: He then draws his secondcard, either from the face up cards or from the top of the deck. (See Train Car Cards for special rules for Locomotive cards). Claim a Route â€“ The player may claim a route on the board by playing a set of Train Car cards that match the color and length of the route andthen placing one of his colored trains on each space of this route. He then records his score by moving his Scoring Marker the appropriate numberof spaces (see Route Scoring Table) along the Scoring Track on the board. Draw Destination Tickets â€“ The player draws 3 Destination Tickets from the top of the deck. He must keep at least one of them, but he may keeptwo or all three if he chooses. Any returned cards are placed on the bottom of the deck. T rain Car CardsThere are 8 types of regular Train Car cards, plus Locomotive cars. The colors of each type of Train Car card match various rou tesbetween cities on the board â€“ Purple, Blue, Orange, White, Green, Yellow, Black, andRed.\n",
            "Distance: 0.557116687297821\n",
            "\n",
            "Document: /content/PDFs/ticket_to_ride.pdf\n",
            "Chunk: In the unlikely event that there are no cards left in the deck and there are no discards(because players are hoarding many cards in their hands), a player cannot draw TrainCar cards. Instead he may only claim a route or draw Destination Ticket cards. Claiming RoutesTo claim a route, a player must play a set of cards equal to the number of spaces in theroute. A set of cards must be of the same type. Most routes require a specific type of set. For example a Blue route must be claimed using blue-colored Passenger Car cards. Someroutes â€“ those that are Gray colored â€“ can be claimed using a set of cards of any one color. When a route is claimed, the player places one of his plastic trains in each of the spacesof the route. All the cards in the set used to claim the route are then discarded. A player may claim any open route on the board. He is never required toconnect to any of his previously played routes.\n",
            "Distance: 0.845978856086731\n",
            "\n",
            "Document: /content/PDFs/ticket_to_ride.pdf\n",
            "Chunk: Locomotives are Multi-colored and act as a wild card that can be part of any set ofcards when claiming a route. If a Locomotive card is one of the five face-up cards , theplayer who draws it may only draw one card, instead of two. If, after having drawn onecard the replacement card is a Locomotive, the player cannot take it. If at any time, threeof the five face-up cards are Locomotives, all five cards are immediately discarded andfive new ones are turned face-up to replace them. Note: If a player is lucky enough to get a Locomotive from the top of the deck in a blinddraw, it stills counts as a single card and he may still draw a total of two cards that turn. A player may have any number of cards in his hand at any time. When the deck is exhausted, the discards are reshuffled into a new draw pile deck. Thecards should be shuffled thoroughly, since all the cards have been discarded in sets.\n",
            "Distance: 0.9376686811447144\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"How many types of regular Train Car cards are there?\"\n",
        "answer, relevant_chunks = query_documents(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\\n-----\\n\")\n",
        "print(f\"Generated answer: {answer}\\n\\n-----\\n\")\n",
        "print(\"Relevant chunks:\")\n",
        "for chunk in relevant_chunks:\n",
        "    print(f\"Document: {chunk['document']}\")\n",
        "    print(f\"Chunk: {chunk['chunk']}\".replace(\"\\n\", \"\"))\n",
        "    print(f\"Distance: {chunk['distance']}\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "629d58acfb1d4b04b1b44391c35bc469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bd92400b09b4067a682fcfa2d1abf69",
              "IPY_MODEL_8ca9341fc87c430fa398b2affa3c3fc5",
              "IPY_MODEL_9b1d1adfc800468a8e0dd45dcea31ed1"
            ],
            "layout": "IPY_MODEL_31c63eb1029744cfaf0b6975484e2f7f"
          }
        },
        "4bd92400b09b4067a682fcfa2d1abf69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d77dd6626fe747e6869558b9083f4b43",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6bc35900d38e467cb647d80bc58c6add",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "8ca9341fc87c430fa398b2affa3c3fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04b85362a05d47639832ddb43cbe4d61",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d59bb55498a44e9583d36359c7dfd194",
            "value": 2
          }
        },
        "9b1d1adfc800468a8e0dd45dcea31ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a22824f74ba343bd8ed6193dc53033a8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_feef4d5202624afbb84c16d20a1b271b",
            "value": "â€‡2/2â€‡[00:21&lt;00:00,â€‡â€‡9.00s/it]"
          }
        },
        "31c63eb1029744cfaf0b6975484e2f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d77dd6626fe747e6869558b9083f4b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc35900d38e467cb647d80bc58c6add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04b85362a05d47639832ddb43cbe4d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d59bb55498a44e9583d36359c7dfd194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a22824f74ba343bd8ed6193dc53033a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feef4d5202624afbb84c16d20a1b271b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}